"""
å®æ—¶è¯­éŸ³è¯†åˆ«åº”ç”¨
"""

import streamlit as st
import numpy as np
import queue
import time
from src.asr.audio_capture import AudioCapture
from src.asr.audio_processor import AudioProcessor
from src.asr.funasr_recognizer import FunASRRecognizer

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å®æ—¶è¯­éŸ³è¯†åˆ«",
    page_icon="ğŸ¤",
    layout="wide"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main {
        background-color: #f5f5f5;
    }
    .stButton>button {
        width: 100%;
        background-color: #4CAF50;
        color: white;
        padding: 10px;
        border: none;
        border-radius: 5px;
        cursor: pointer;
    }
    .stButton>button:hover {
        background-color: #45a049;
    }
    .recording-status {
        text-align: center;
        font-size: 1.2em;
        margin: 20px 0;
    }
    .result-box {
        background-color: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        margin: 20px 0;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–ç»„ä»¶
@st.cache_resource
def init_components():
    audio_capture = AudioCapture()
    audio_processor = AudioProcessor()
    recognizer = FunASRRecognizer()
    return audio_capture, audio_processor, recognizer

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'recording' not in st.session_state:
    st.session_state.recording = False
if 'recognized_text' not in st.session_state:
    st.session_state.recognized_text = ""
if 'audio_chunks' not in st.session_state:
    st.session_state.audio_chunks = []

# åˆå§‹åŒ–ç»„ä»¶
audio_capture, audio_processor, recognizer = init_components()

# æ ‡é¢˜
st.title("ğŸ¤ å®æ—¶è¯­éŸ³è¯†åˆ«")

# å½•éŸ³æ§åˆ¶
col1, col2 = st.columns(2)
with col1:
    if st.button("å¼€å§‹å½•éŸ³", disabled=st.session_state.recording):
        st.session_state.recording = True
        st.session_state.audio_chunks = []
        audio_capture.start()
with col2:
    if st.button("åœæ­¢å½•éŸ³", disabled=not st.session_state.recording):
        st.session_state.recording = False
        audio_capture.stop()

# æ˜¾ç¤ºå½•éŸ³çŠ¶æ€
if st.session_state.recording:
    st.markdown('<div class="recording-status">ğŸ¤ æ­£åœ¨å½•éŸ³...</div>', unsafe_allow_html=True)
else:
    st.markdown('<div class="recording-status">â¸ï¸ å½•éŸ³å·²åœæ­¢</div>', unsafe_allow_html=True)

# æ˜¾ç¤ºè¯†åˆ«ç»“æœ
st.markdown('<div class="result-box">', unsafe_allow_html=True)
st.markdown("### è¯†åˆ«ç»“æœ")
st.markdown(st.session_state.recognized_text)
st.markdown('</div>', unsafe_allow_html=True)

# ä¸»å¾ªç¯
if st.session_state.recording:
    try:
        # è¯»å–éŸ³é¢‘æ•°æ®
        audio_data = audio_capture.read()
        if audio_data is not None:
            # å¤„ç†éŸ³é¢‘æ•°æ®
            processed_audio = audio_processor.process(audio_data)
            # è¯†åˆ«éŸ³é¢‘
            text = recognizer.recognize(processed_audio)
            if text:
                st.session_state.recognized_text += text + " "
                st.experimental_rerun()
    except Exception as e:
        st.error(f"å¤„ç†éŸ³é¢‘æ—¶å‡ºé”™: {str(e)}")
        st.session_state.recording = False

# ä½¿ç”¨è¯´æ˜
st.markdown("""
### ä½¿ç”¨è¯´æ˜
1. ç‚¹å‡»"å¼€å§‹å½•éŸ³"æŒ‰é’®å¼€å§‹å½•éŸ³
2. è¯´è¯æ—¶ï¼Œè¯†åˆ«ç»“æœä¼šå®æ—¶æ˜¾ç¤º
3. ç‚¹å‡»"åœæ­¢å½•éŸ³"æŒ‰é’®åœæ­¢å½•éŸ³
4. è¯†åˆ«ç»“æœä¼šä¿ç•™åœ¨é¡µé¢ä¸Š
""") 